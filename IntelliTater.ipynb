{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IntelliTater",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMsU3uuMSzXxu/EEh5XFxXN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arc-blroth/IntelliTater/blob/main/IntelliTater.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hiCkXOIb8hj"
      },
      "source": [
        "\n",
        "# IntelliTater\n",
        "\n",
        "IntelliTater is a 100% automated way to generate tater background splash screens for IntelliJ-family IDEs.\n",
        "\n",
        "The algorithm used is currently taliored to the 2021.x style of splashes, but it shouldn't be too hard to edit the algorithm to handle other versions.\n",
        "\n",
        "## Usage\n",
        "\n",
        "1. Find the splash screen for your IDE inside `lib/resources.jar` from the root directory of your IDE installation. The filenames of the splash screen images vary between IDEs and Community/Ultimate editions. For IntelliJ IDEA Community Edition, the files are named `idea_community_logo.png` and `idea_community_logo@2x.png` for the splash screen and large splash screen respectively.\n",
        "\n",
        "   The algorithm has mostly been tested on the double sized splash screens. To generate a normal sized splash screen, you can resize the 2x splash screen or tweak the `TEXT_DILATION_KERNEL` and `TEXT_BLUR_KERNEL` variables in the first cell.\n",
        "2. Upload that splash screen to Colab (or copy it so that your Jupyter instance can find it), and rename it to `splash.png`.\n",
        "3. If you want some background other than the default tater background, also upload a file named `background.png`.\n",
        "4. Run the three cells below this README. (The other cells were random experiments to figure out better ways to separate the background of the splash from the foreground)\n",
        "5. Download `out.png` from this notebook, and replace the splash file in `resources.jar` with that. (You might have to refresh the file list in Colab before `out.png` shows up)\n",
        "6. Start your IDE and witness the power of Tiny Potato!\n",
        "\n",
        "## Disclaimers\n",
        "\n",
        "\"Jetbrains\", \"IntelliJ\", and \"IntelliJ IDEA\" are trademarks of [Jetbrains](www.jetbrains.com), which has not endorsed this taterfier.\n",
        "\n",
        "The Tiny Potato is inspired from [Botania](https://botaniamod.net/).\n",
        "\n",
        "The default background used in this notebook was created by [Arc-blroth](http://github.com/Arc-blroth) and is licensed under [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/legalcode). It is a derivative of the [Fabric Splash](https://github.com/FabricMC/community/blob/c217e169ccab96d4eed86606df1c6456879382d3/media/tater-wall/png/fabric-splash.png) by [gdude2002](https://github.com/gdude2002), licensed under the same license.\n",
        "\n",
        "## Special Thanks\n",
        "\n",
        "To [ramidzkh](https://github.com/ramidzkh), whose \"who did this\" post sparked the first tater splash.\n",
        "\n",
        "To [Gudenau](https://github.com/gudenau), who asked me to make more of these.\n",
        "\n",
        "To everyone else who downloaded and used the first tater splashes. Though it may have been deleted from Fabricord, #tiny-potato will live in our hearts forever!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zymu3woVrUuT"
      },
      "source": [
        "!wget https://resources.jetbrains.com/storage/products/jetbrains/docs/jetbrains-logos-pack.zip -O jetbrains.zip\n",
        "!unzip jetbrains.zip -d ./jetbrains\n",
        "!mv ./jetbrains/jetbrains-logos/blackandwhite/jetbrains-blackandwhite.png ./\n",
        "!rm -rf ./jetbrains/\n",
        "!rm jetbrains.zip\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "\n",
        "# Logo text adjustment factors\n",
        "# ----------------------------\n",
        "# These are used to compensate for the fact that the\n",
        "# text in the original splash is rendered subpixel, but\n",
        "# OpenCV can only reliably detect to pixel accuracy.\n",
        "#\n",
        "# The mask that controls what parts of the image is\n",
        "# interpreted as \"logo\" text is expanded by the dilation\n",
        "# kernal and then filter blurred by the blur kernel.\n",
        "TEXT_DILATION_KERNEL = (1, 1)\n",
        "TEXT_BLUR_KERNEL = (2, 2)\n",
        "TEXT_BLUR_CUTOFF = 2"
      ],
      "execution_count": 431,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7xjv9qOgXbC"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from os import path\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "assert path.exists(\"splash.png\"), \"No `splash.png` file found!\"\n",
        "\n",
        "# Download background.png if it doesn't already exist\n",
        "if not path.exists(\"background.png\"):\n",
        "    print(\"No `background.png` file found, downloading default tater background...\")\n",
        "    !wget https://raw.githubusercontent.com/Arc-blroth/IntelliTater/main/intellitater_wall.png -O background.png -q\n",
        "\n",
        "# Read images\n",
        "img = cv2.cvtColor(cv2.imread(\"splash.png\"), cv2.COLOR_BGR2RGB)\n",
        "background = cv2.cvtColor(cv2.imread(\"background.png\"), cv2.COLOR_BGR2RGB)\n",
        "background = background[0 : img.shape[0], 0 : img.shape[1]]\n",
        "\n",
        "# Step 0: Crop logo\n",
        "logo = cv2.cvtColor(\n",
        "    cv2.imread(\"jetbrains-blackandwhite.png\", cv2.IMREAD_UNCHANGED), cv2.COLOR_BGRA2RGBA\n",
        ")\n",
        "logo[np.all(logo == (0, 0, 0, 0), axis=-1)] = (255, 255, 255, 255)\n",
        "logo_thresh = cv2.cvtColor(logo, cv2.COLOR_RGBA2GRAY)\n",
        "_, logo_thresh = cv2.threshold(logo_thresh, 127, 255, cv2.THRESH_BINARY_INV)\n",
        "contours, _ = cv2.findContours(logo_thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "x, y, w, h = cv2.boundingRect(contours[0])\n",
        "logo = logo[y : y + h, x : x + w]\n",
        "logo = cv2.cvtColor(logo, cv2.COLOR_RGBA2RGB)"
      ],
      "execution_count": 432,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJOwRKRFnMfo"
      },
      "source": [
        "# Step 1: Figure out where text is\n",
        "text_mask = cv2.inRange(img, np.array([200, 200, 200]), np.array([255, 255, 255]))\n",
        "text_mask = cv2.dilate(text_mask, np.ones(TEXT_DILATION_KERNEL, np.uint8), iterations=1)\n",
        "text_mask = cv2.filter2D(text_mask, -1, np.ones(TEXT_BLUR_KERNEL, np.float32) / TEXT_BLUR_CUTOFF)\n",
        "\n",
        "# Step 2: Figure out where logo is\n",
        "logo_mask = cv2.inRange(img, np.array([0, 0, 0]), np.array([10, 10, 10]))\n",
        "contours, _ = cv2.findContours(logo_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "for contour in contours:\n",
        "  x, y, w, h = cv2.boundingRect(contour)\n",
        "  cv2.rectangle(logo_mask, (x, y), (x + w - 1, y + h - 1), (255, 255, 255), -1)\n",
        "\n",
        "# Step 3: Feather and combine\n",
        "# See https://stackoverflow.com/a/55970627\n",
        "float_mask = cv2.cvtColor(text_mask, cv2.COLOR_GRAY2BGR).astype(np.float32) / 255\n",
        "float_img = img.astype(np.float32) / 255\n",
        "float_background = background.astype(np.float32) / 255\n",
        "# For better masking alpha is multiplied by how close the color is to pure white\n",
        "actual_mask = np.zeros(float_img.shape)\n",
        "actual_mask[:, :, 0] = np.average(float_img * float_mask, axis=2)\n",
        "actual_mask[:, :, 1] = actual_mask[:, :, 0]\n",
        "actual_mask[:, :, 2] = actual_mask[:, :, 0]\n",
        "out = float_background * (1 - actual_mask) + np.ones(float_img.shape) * actual_mask\n",
        "out = (out * 255).astype(np.uint8)\n",
        "cv2.copyTo(img, logo_mask, out)\n",
        "\n",
        "cv2.imwrite(\"out.png\", cv2.cvtColor(out, cv2.COLOR_RGB2BGR))\n",
        "# cv2.imwrite(\"logo_found_img.png\", cv2.cvtColor(logo_found_img, cv2.COLOR_RGB2BGR))\n",
        "print(\"Taterification complete!\")\n",
        "\n",
        "if \"google.colab\" in str(get_ipython()):\n",
        "    from ipywidgets import widgets\n",
        "    from IPython.display import display\n",
        "    from IPython.core.display import HTML\n",
        "    from google.colab import files\n",
        "\n",
        "    def download_out(e):\n",
        "        files.download(\"out.png\")\n",
        "\n",
        "    download_button = widgets.Button(description=\"Download `out.png`\")\n",
        "    download_button.on_click(download_out)\n",
        "    download_button.margin = \"20\"\n",
        "    display(widgets.VBox([widgets.HBox([download_button])]))\n",
        "\n",
        "plt.imshow(out)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urT-8FWDin9w"
      },
      "source": [
        "-- Other Experiments --"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ub-bhMP7nI7b"
      },
      "source": [
        "# Find logo in the image using template matching\n",
        "# based on https://www.pyimagesearch.com/2015/01/26/multi-scale-template-matching-using-python-opencv/\n",
        "# but scales the template rather than the image and uses binary search instead of brute force steps\n",
        "def find_scaled_template(image, template, lower_size, upper_size, steps):\n",
        "    (tH, tW) = template.shape[:2]\n",
        "    step = (upper_size - lower_size) / 2\n",
        "    scale = lower_size + step / 2\n",
        "    step /= 2\n",
        "    found = None\n",
        "\n",
        "    for i in range(steps):\n",
        "        lower_scale = scale - step / 2\n",
        "        upper_scale = scale + step / 2\n",
        "        lower_resized = cv2.resize(\n",
        "            template,\n",
        "            (\n",
        "                int(template.shape[1] * lower_scale),\n",
        "                int(template.shape[0] * lower_scale),\n",
        "            ),\n",
        "        )\n",
        "        upper_resized = cv2.resize(\n",
        "            template,\n",
        "            (\n",
        "                int(template.shape[1] * upper_scale),\n",
        "                int(template.shape[0] * upper_scale),\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        lower_result = cv2.matchTemplate(image, lower_resized, cv2.TM_CCORR_NORMED)\n",
        "        upper_result = cv2.matchTemplate(image, upper_resized, cv2.TM_CCORR_NORMED)\n",
        "\n",
        "        _, lower_max_val, _, lower_max_loc = cv2.minMaxLoc(lower_result)\n",
        "        _, upper_max_val, _, upper_max_loc = cv2.minMaxLoc(upper_result)\n",
        "        if lower_max_val > upper_max_val:\n",
        "            found = (lower_max_val, lower_max_loc, lower_scale)\n",
        "\n",
        "        else:\n",
        "            found = (upper_max_val, upper_max_loc, upper_scale)\n",
        "\n",
        "        scale = found[2]\n",
        "        step /= 2\n",
        "\n",
        "    _, maxLoc, r = found\n",
        "    return (int(maxLoc[0]), int(maxLoc[1]), int(tW * scale), int(tH * scale))\n",
        "\n",
        "\n",
        "logo_found_img = img.copy()\n",
        "x, y, w, h = find_scaled_template(logo_found_img, logo, 0.1, 0.2, 10)\n",
        "logo_found_img = cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
        "plt.imshow(logo_found_img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXA-0_umfAs4"
      },
      "source": [
        "!apt install tesseract-ocr\n",
        "!pip install pytesseract"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99GmojzpnSwx"
      },
      "source": [
        "# OCR\n",
        "import pytesseract\n",
        "\n",
        "# image is inverted because tesseract expects black-on-white\n",
        "inv_img = cv2.bitwise_and(img, img, mask=mask)\n",
        "inv_img = 255 - inv_img\n",
        "\n",
        "data = pytesseract.image_to_data(inv_img, output_type=pytesseract.Output.DICT)\n",
        "for i in range(len(data[\"level\"])):\n",
        "    if data[\"text\"][i]:\n",
        "        x, y, w, h = (\n",
        "            data[\"left\"][i],\n",
        "            data[\"top\"][i],\n",
        "            data[\"width\"][i],\n",
        "            data[\"height\"][i],\n",
        "        )\n",
        "        cv2.rectangle(inv_img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "\n",
        "plt.imshow(inv_img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}